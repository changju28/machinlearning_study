지도학습에는 분류와 회귀가 있다

분류는 데이터의 결과을 알고 싶을 때 사용
    ex) 스펨 메일인지 아닌지 을 분류 하고 싶은 때

회귀는 데이터에 따른 수치를 알고싶을 때 사용
    ex) 아파트 가격의 평균을 구하고 싶은 때
    종류: 선형회귀, 다중 선형 회귀, 다항 회귀, 로지스틱 회귀

    선형회귀: 예외적인 데이터에 민감하다
        ex) 이메일 분류 시 기준을 두고 기준의 절반을 넘어갈 시 스펨 아닐 시 메일 구분 하면 되지만
            이메일을 분류 하는 기준 하나가 눈에 띄게 높은 가설함수를 나타낸다면 메일의 기준이 높아져
            분류하기에 어려움이 있다.


로지스틱 회귀 : 선형회귀가 데이터에 가장 잘 맞는 일차 함수를 찾는거라면, 로지스틱 회귀는 데이터에 잘 맞는 일차 함수가 아니라 데이터에 가장
              잘 맞는 시그모이드 함수를 찾는 것

                                1
시그모이드 함수의 식 =  S(x) = ----------
                             1 + e^-x

                      e = 2.718 (양수)

시그모이드 함수의 그래프 = s자의 곡선

시그모이드 함수의 특징
    1. 무조건 0과 1사이의 결과를 낸다
        ex) e^ -무한대 는 0이기 때문에 결과는 1이 나오고
            e^ -(-무한대) 는 2.718^무한대 이기 때문에 결과 값은 1보다 작은 0의 소수점 이라 0이 나오는 것이다

    2. 선형 회귀는 예외적인 데이터 하나에 가설 함수가 너무 민감하게 반응 하지만 시그모이드 함수는 동떨어진 데이터 하나가 있어도 크게 영향을 받지 않는다.



로지스틱 회귀의 손실 함수
    - 로그 손실(log-loss / cross entropy)
        공식: logloss(h0(x), y) = -ylog(h0(x)) - (1-y)log(1-h0(x))






