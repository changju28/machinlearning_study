선형회귀 : 데이터를 가장 잘 대변해 주는 선을 찾아내는 알고리즘

학습 : 지도학습 (분류 / 회귀)
지도학습 : 회귀

학습 데이터
1. 목표변수: 맞추려고 하는 값 (target varialble / output variable)
2. 입력변수: 맞추는데 사용하는 값 (input variable / feature:특징)

ex) 입력변수: 집크기
    목표변수: 집값

선형회귀는 선을 찾아내기 때문에 일차함수를 사용하고 공식은 h(x) = 0o + 01x1 ... 이런식

선형 회귀 : 가장 적절한 가설함수(계수값과 상수 값)을 찾아내는 것


가설함수 평가법
1. 평균 제곱 오차 (MSE) : 최적선과 목표변수간의 오차 범위를 구한 후 각 오차의 제곱 을 모두 더한 후 데이터 갯수를 나누어 주는 평가법
    # 제곱하는 이유
        1. 오차가 마이너스가 나올 시 더한 값이 줄어들기 때문에 제곱을 하여 마이너스를 날려주기 위함
        2. 제곱을 하므로서 오차범위의 크기를 증가 시켜 더 정확한 값을 얻기 위함(페널티를 주기 위함)
                  m
        공식 : 1/m ∑ (h0(x(i)) - y(i))^2
                 i=1
        가설함수 - 기존결과값을 빼서 오차를 구한후 제곱을 한 후 모두 더해 데이터 갯수 m으로 나눠서 평균을 구함

2. 손실 함수(Loss Function)
    - 가설 함수의 성능을 평가하는 함수
    - 손실 함수가 작으면: 가설 함수가 데이터에 잘 맞다
    - 손실 함수가 크면: 가설 함수가 데이터에 잘 안 맞다.
              m
    공식 : 1/2m ∑ (h0(x(i)) - y(i))^2
              i=1

손실 함수의 아웃풋을 최소화 하기 위해선 경사 하강법(Gradient Descent)을 사용

경사 하강법 : 경사의 방향과 크기에 따라 극소점으로 나아가는 방식

모델 평가하기
1. 평균 제곱근 오차: 평균 제곱 오차에 루트를 씌운것
(기존에 평균 제곱 오차는 제곱을 해줫기 때문에 구별하기 어려워서 다시 루트르 씌어 제곱을 벗겨주기 위함)

학습과 평가를 위한 데이터를 나눈다.

학습데이터(training set) : 모델을 학습하기 위한 데이터

평가데이터(test set) : 모델을 평가하기 위한 데이터

